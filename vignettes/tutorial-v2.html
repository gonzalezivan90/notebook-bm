<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Gonzalez, Ivan; Muñoz, Carlos; Noguera, Elkin PhD." />


<title>Biomodelos application notebook v1.0 Vignette</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Biomodelos application notebook v1.0
Vignette</h1>
<h4 class="author">Gonzalez, Ivan; Muñoz, Carlos; Noguera, Elkin
PhD.</h4>
<h4 class="date">2022-04-18; updated 2023-03-11</h4>



<p>This work is distributed under the
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC-BY-NC-SA
4.0</a> license.<br />
<br />
</p>
<div id="preface" class="section level1">
<h1>Preface</h1>
<p>This is the preface section for <em>Biomodelos</em> vignette.</p>
<p>Click
<a href="http://biomodelos.humboldt.org.co/" target="_blank">here</a> to
access the webpage</p>
<p>Check the <code>R package resources code  here</code></p>
</div>
<div id="introduction" class="section level1">
<h1><a id="Intro"></a>Introduction</h1>
<p>Biomodelos description here</p>
<p>Here reproduce your analysis. For more details, including on SDMs,
please see our
<a href="https://journals.plos.org/plosone/article%3Fid=10.1371/journal.pone.0214522" target="_blank">initial
publication</a><sup>1</sup> in <em>PLOS ONE</em></p>
<p>Here some references: 1. Kass, J.M., Vilela, B., Aiello-Lammens,
M.E., Muscarella, R., Merow, C., Anderson, R.P. (2018).
<em>Wallace</em>: A flexible platform for reproducible modeling of
species niches and distributions built for community expansion.
<em>Methods in Ecology and Evolution</em>, 9(4),1151-1156. <a href="https://doi.org/10.1371/journal.pone.0214522" class="uri">https://doi.org/10.1371/journal.pone.0214522</a></p>
</div>
<div id="setup" class="section level1">
<h1><a id="Setup"></a>Setup</h1>
<div id="installing-the-code" class="section level3">
<h3>Installing the Code</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">+</span><span class="dv">2</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># AND </span></span></code></pre></div>
<p>Operative system</p>
<p>An example with Terminal in MacOS.</p>
<p>To exit <em>Wallace</em>, hit ‘Escape’ while in the <code>R</code>
console and close the browser window, or click the quit button in the
top right corner of the GUI. Note: If you close the browser window
running <em>Wallace</em>, <strong>your session will be over and all
progress will be lost</strong>. See <a href="#Save">Save &amp; Load
Session</a> for how to save your work and be able to restart your
analysis.</p>
</div>
<div id="setting-up-java-version-of-maxent" class="section level3">
<h3><em>Setting up Java version of Maxent</em></h3>
<p><em>Wallace v2.0</em> includes two options to run Maxent models:
maxnet and maxent.jar. The former, which is an <code>R</code>
implementation of Maxent and fits the model leveraging the package
<code>glmnet</code>, is now the default and does not require running
Java (see Phillips et al. 2017). The latter, which is the original Java
implementation, runs the <code>maxent()</code> function in the package
<code>dismo</code>, which in turn relies on tools from the package
<code>rJava</code>. When using <code>dismo</code> to run maxent.jar, the
user must place the maxent.jar file in the /java directory of the
<code>dismo</code> package root folder. You can download Maxent
<a href="https://biodiversityinformatics.amnh.org/open_source/maxent/" target="_blank">here</a>
and find maxent.jar, which runs Maxent, in the downloaded folder. You
can find the directory path to dismo/java by running system.file(‘java’,
package=“dismo”) in the <code>R</code> console. Simply copy maxent.jar
and paste it into this folder. If you try to run Maxent in
<em>Wallace</em> without the file in place, you will get a warning
message in the log window and Maxent will not run. Also, if you have
trouble installing <code>rJava</code> and making it work, there is a bit
of troubleshooting on the <em>Wallace</em> Github repository
<a href="https://github.com/wallaceEcoMod/wallace/blob/master/README.md" target="_blank">README</a>
that hopefully should help.</p>
</div>
</div>
<div id="orientation" class="section level1">
<h1><a id="Orientation"></a>Orientation</h1>
<p>We’ll begin with an orientation of the <em>Wallace</em> interface.
After running run_wallace(), <em>Wallace</em> opens to the
<strong>Intro</strong> page. The “About” tab contains background
information about the program. The “Team” tab has details about the
developers and collaborators who contributed to <em>Wallace</em>. The
“How to Use” tab contains a brief user manual, which is an abridged
version of this vignette without a worked example. The “Load Prior
Session” tab is for loading a prior session, which we will cover <a href="#Save">later</a>.</p>
<p>At the top in the orange panel are the <strong>Components</strong>,
which represent the steps of analysis. Each of these component tabs
opens to the corresponding step. Within each component are several
<em>Modules</em>, which are discrete analysis options within the
components. To the left in the gray panel is the <em>Wallace</em>
WORKFLOW, outlining the version number, components (numbered), and
modules (bulleted) currently included.</p>
<p>Click on the component tab <strong>Occ Data</strong>, select a
module, and consult the schematic below showing the different parts of
the <em>Wallace</em> interface.</p>
<p>(<strong>1</strong>) These are the components. You will be stepping
sequentially through them. <em>Wallace v2</em> now includes a Support
button (<strong>1a</strong>), which links to the Google Group, email,
website, and the Github page to report issues, as well as the quit
button (<strong>1b</strong>), which will end the session.<br />
(<strong>2</strong>) This is the toolbar with all the user interface
controls, such as buttons, text inputs, etc. You can see that the module
<em>Query Database (Present)</em> is currently selected. You’ll see that
two other modules exist for this component: <em>Query Database
(Paleo)</em> and <em>User-specified</em>. This last module lets you
upload your own occurrence data. Try choosing it instead and notice that
the toolbar changes, then click back to <em>Query Database
(Present)</em>.<br />
Both the <strong>Component</strong> and <em>Module</em> have question
mark buttons (?) next to the title text. Clicking these will link to the
respective guidance texts.<br />
Within this toolbar, you can find the module name and the <code>R</code>
packages it uses (<strong>2a</strong>), as well as the control panel for
the selected module (<strong>2b</strong>). Modules can be contributed by
other researchers and the developers; CRAN links and documentation are
at the bottom.<br />
(<strong>3</strong>) The right side is the visualization space. Any
functions performed will trigger a message in the log window
(<strong>3a</strong>). This window will also display any error messages.
<em>Wallace v2.0.5</em> now allows the user to load multiple species. If
multiple species are loaded, toggle and select between species using the
species drop-down menu (<strong>3b</strong>).<br />
The visualization space includes several tabs (<strong>3c</strong>),
including an interactive map, occurrence records table, results window,
model and component guidance text windows, and a tab for saving outputs
and the current session.<br />
</p>
<p>At this stage of the analysis, no results exist, and you have no data
yet for the table, but you can view the <strong>Component
Guidance</strong> and <em>Module Guidance</em> text now. This text was
written by the developers to prepare users for each component and module
<em>theoretically</em> (why we should use the tools) and
<em>methodologically</em> (what the tools do). The guidance text also
references scientific papers from the literature for more detailed
reading. Please get into the habit of consulting these before
undertaking analyses—and discussing them with your peers—-as this should
give you a more solid foundation for moving forward.<br />
</p>
<p>The next tab in the visualization space is <strong>Save</strong>. At
any point along the workflow, selecting “Save session” within this tab
will save the progress as a .rds file. This file can be loaded back into
<code>wallace</code> to resume analysis. If at any point during the
vignette you need to pause, jump to <a href="#Save">Save &amp; Load
Session</a> to learn how to save and load your <em>Wallace</em> session.
This tab is also where you will be able to download and save results.
The session code, metadata, and package citations can be downloaded
within <strong>Component: Reproduce</strong>.</p>
<p>Now let’s begin our analysis.<br />
</p>
<p>We’ll be modeling the ranges of two mammal species of the genus
<em>Bassaricyon</em>, which are members of the family Procyonidae that
includes raccoons. <em>Bassaricyon neblina</em>, or the olinguito, is
found in tropical montane areas of western Colombia and Ecuador in South
America. The olinguito gained species status in 2013 when it was
identified from existing museum specimens and is currently a species of
concern listed as “Near Threatened” by the IUCN (Helgen et al. 2020).
<em>Bassaricyon alleni</em>, or the eastern lowland olingo, is a
relative of the olinguito and has a broader range throughout northern
South America; it is currently listed as “Least Concern” by the IUCN
(Helgen et al. 2016).</p>
</div>
<div id="obtain-occurrence-data" class="section level1">
<h1><a id="Occ"></a>Obtain Occurrence Data</h1>
<p>Make sure you are in the first component (<strong>Obtain Occurrence
Data</strong>) and click to read the component guidance text. There are
three modules available for obtaining occurrence data: <em>Query
Database (Present)</em>, <em>Query Database (Paleo)</em>, and
<em>User-Specified</em>. Choose a module and click on the module
guidance text. Notice the module guidance text changes as you select
among the three modules. Read through these to get a better
understanding of how occurrence data is typically obtained and how
<code>wallace</code> implements it.</p>
<p>Let’s proceed to get some occurrence data. We’ll be using present
occurrences (as opposed to those from the deep past via fossil data,
etc.) and therefore use Module: <em>Query Database (Present)</em>. There
is a selection of databases to choose from, as well as the option to
return only those occurrences that contain information on coordinate
uncertainty (which can be useful to filter by later). If you have a GBIF
User ID, checking the “Include Data Source” box will allow you to log in
with your username and password to download a DOI for the dataset. In
order for this to work, you will need to install the R-package
<code>occCite</code> prior to running Wallace. Since
<code>occCite</code> is a suggested package, it will not install
automatically like the other package dependencies.</p>
<p>Choose GBIF (the Global Biodiversity Information Facility—one of the
largest storehouses for biodiversity data), keep uncertainty unchecked,
type in <em>Bassaricyon neblina</em> into the scientific name box, set
the maximum number of occurrences to 200, and click <strong>Query
Database</strong>.</p>
<p>After the download is complete, the log window will contain
information on the analysis performed. Your search should return at
least 58 records (numbers recorded at the time of writing), but after
accounting for records without coordinate information (latitude,
longitude) and removing duplicate records, at least 43 should remain.
This species has relatively few records, so setting the maximum to 200
is sufficient, but for modeling with data-rich species, 200 may not be
enough for adequately sampling the known range, and the maximum can be
increased. **<em>Numbers may be different as more records are added to
GBIF.</em></p>
<p>Now click on the “Occurrences” tab to view more information on the
records. The developers chose the fields that are displayed based on
their general relevance to studies on species ranges. Note that you can
download the full table with all fields.</p>
<p>Click the “Save” tab. The first save box allows you to download your
session. It is available in all the components and modules (See <a href="#Save">Save &amp; Load Session</a> section for more details). The
download options below the Save Session box change depending on which
component is selected. Here, you can get a .csv file of the records just
acquired. The first option will download the original database fields
for every downloaded record (before any filtering). The second option
downloads the current table. The third option, “Download all data”, is
unavailable at this point, but that will change after we include our
second species.</p>
<p><em>Note to Chrome users: If you find the map is loading incorrectly
after downloading an object, specifically the corner tile loads but the
rest of the map is gray, closing the download bar at the bottom of the
page should reset the map and fix the problem.</em></p>
<p>A major improvement in <em>Wallace</em> v2.0 from previous versions
is the ability to consider multiple species (separately) in the same
session. Let’s add another species to model.</p>
<p>Aside from GBIF, you can query the Vertnet (for vertebrate data) and
newly added BIEN (for botantical data) for species occurrence records.
In the second module <em>Query Database (Paleo)</em>, you can query
PaleobioDB databases for fossil records by selecting a time interval and
species. Specific packages may have to be downloaded prior to loading
Wallace to use these (e.g., <code>BIEN</code> and
<code>paleobioDB</code>).</p>
<p>If you have your own occurrence data, you can import it using the
third module, <em>User-specified</em>. Your occurrence data file must be
a .csv with the columns “scientific_name”, “longitude”, and “latitude”,
explicitly named and in that order. It may have other columns, but those
must be the first three. You also have the option to specify the
delimiter and separator of your file.</p>
<p>We’ll continue with GBIF occurrence data. Search the database for
<em>Bassaricyon alleni</em> (eastern lowland olingo), keeping the max
set at 200. This should return at least 81 records and after cleaning
should come to at least 42 records. You might have noticed that the log
window was updated, but the map remains the same. The map will not
change automatically, as <em>Bassaricyon neblina</em> is still selected
in the Species menu. Toggle between species to show the map for
<em>Bassarricyon alleni</em>.</p>
<p>Click back to the “Save” tab. Notice that the third option is now
available.</p>
</div>
<div id="obtain-environmental-data" class="section level1">
<h1><a id="Env"></a>Obtain Environmental Data</h1>
<p>Next, you will need to obtain environmental variables for the
analysis. The values of the variables are extracted for the occurrence
records, and this information is provided to the model. These data are
in raster form, which simply means a large grid where each grid cell
specifies a value. Rasters can be displayed as colored grids on maps
(we’ll see this later). Click on the component <strong>Env
Data</strong>. The first module, <em>WorldClim Bioclims</em>, lets you
download bioclimatic variables from
<a href="https://www.worldclim.org/" target="_blank">WorldClim</a>, a
global climate database of interpolated climate surfaces derived from
weather station data at multiple resolutions. The interpolation is
better for areas with more weather stations (especially in developed
countries), and more uncertainty exists in areas with fewer stations.
The
<a href="https://www.worldclim.org/data/bioclim.html" target="_blank">bioclim</a>
variables are summaries of temperature and precipitation that have been
proposed to have general biological significance. You have the option to
specify a subset of the 19 total variables to use in the analysis.</p>
<p>The second module, <em>ecoClimate</em>, is a module included with v2
that includes paleoclimate reconstructions. It accesses climatic layers
from the PMIP3 – CMIP5 projects from
<a href="https://www.ecoclimate.org/" target="_blank">ecoClimate</a>.
Users can select from Atmospheric Oceanic General Circulation Models and
choose a temporal scenario to use. All ecoClimate layers have a
resolution of 0.5 degrees, whereas WorldClim allows resolution options
of 30 arcsec, 2.5 arcmin, 5 arcmin, or 10 arcmin.</p>
<p>The third module, <em>User-specified</em>, is for uploading your own
rasters into Wallace. These can be continuous, numerical, or categorical
variables to provide to the model.</p>
<p>We’ll be using WorldClim. The first time you use <em>Wallace</em>,
these data are downloaded to a temporary folder on your hard drive;
after that, they will simply be loaded from this local directory (which
will be quicker than downloading from the web). You also have the option
to save to memory for faster processing–this saves the data temporarily
as a RasterBrick in your RAM for <em>Wallace</em> to access. Finer
resolution rasters will take longer to download. The finest resolution
data (30 arcsec) is served in large global tiles when downloading
through <code>R</code> with the <code>raster</code> package (which
<code>wallace</code> uses) and a single tile that corresponds to the map
center will be downloaded. Set the resolution to 30 arcsec and the
latitude and longitude of the map center will be given. To visualize how
well the tile will cover the occurrence points, click the “30 arcsec
tile” box in the bottom left corner of the map. The points outside the
tile will be excluded; you may need to zoom out to see fully.</p>
<p>Although you could download the (very big) 30 arcsec global raster
from the WorldClim website and load it into Wallace (preferably after
cropping it with GIS software or in <code>R</code>), we will instead
choose the 2.5 arcmin bioclimatic variable resolution that Wallace
serves in a global extent to cover all our occurrence points, and we
will keep all 19 bioclimatic variables checked. Note that the selections
made will be performed only for the species selected in the Species Menu
box, unless the “Batch” box is checked.</p>
<p>The “Batch” button will perform the analysis you’ve set up in the
module for all the species you have uploaded. You’ll notice this option
in many of the modules. If you want to perform individualized analyses
for each species (in this case, different environmental variables),
leave “Batch” unchecked. Note: The batch option is not available for 30
arcsec resolution since different tiles may need to be accessed.</p>
<p>Check Batch and Load Env Data.<br />
Notice the progress bar in the bottom-right corner.</p>
<p>After the rasters have loaded, the “Results” tab will display summary
information about them (e.g., resolution, extent, cell number, etc.). In
addition to downloading the rasters, <em>Wallace</em> will also remove
any occurrence points with no environmental values (i.e., points that
did not overlap with grid cells with data in the rasters).</p>
<p>You can download your environmental variables from within the
Download Data section of the “Save” tab.</p>
</div>
<div id="process-occurrence-data" class="section level1">
<h1><a id="Proc"></a>Process Occurrence Data</h1>
<p>The next component, <strong>Process Occs</strong>, gives you access
to some data-cleaning tools. The data you retrieved from GBIF are raw,
and there will almost always be some erroneous points. Some basic
knowledge of the species’ range can help us remove the most obvious
errors. For databases like GBIF that accumulate lots of data from
various sources, there are inevitably some dubious localities. For
example, coordinates might specify a museum location instead of those
associated with the specimen, or the latitude and longitude might be
inverted. In order to eliminate these obviously erroneous records,
select only the points you want to keep for analysis with the module
<em>Select Occurrences On Map</em>. Alternatively, you can also remove
specific occurrences by ID with the module <em>Remove Occurrences by
ID</em>. Even after removing problematic points, those you have left may
be clustered due to sampling bias. This often leads to artifactually
inflated spatial autocorrelation, which can bias the environmental
signal for the occurrence data that the model will attempt to fit. For
example, there might be clustering of points near cities because the
data are mostly from citizen scientists who live in or near them. Or,
the points can cluster around roads because the field biologists who
took the data were either making observations while driving or gained
access to sites from them. The last module, <em>Spatial thin</em> will
help reduce the effects of sampling bias. Unlike other components, in
<strong>Process Occs</strong> the modules are not exclusive, and all can
be used in any order.<br></p>
<p>Make sure <em>Bassaricyon alleni</em> is in the species menu.<br />
We will practice using the first two modules with this species. In the
first module, we will use the polygon-drawing tool to select
occurrences. The polygon drawing tool is useful to draw extents and will
be seen in other modules later on as well.</p>
<p>Click on the polygon icon on the map toolbar.</p>
<p>This opens the drawing tool. Click to begin drawing—each click
connects to the last with a line. Draw a shape around South America,
omitting the record in Bolivia. If you make a mistake in drawing, you
can click “Delete last point” or “Cancel” to start over. To finish
drawing, click again on the first point you made, or click “Finish” in
the drawing tool. This finalizes the shape to use in analysis. Now click
“Select Occurrences” and you will see the point in Bolivia disappear. To
remove the blue shaded polygon, click on the trashcan icon on the map
toolbar and hit “Clear All”. If you are displeased or have made an
error, the red “Reset” button in the module interface will revert back
to the original points. Since we arbitrarily removed the record in
Bolivia, click reset to return to our original dataset.</p>
<p>We will now remove it again, this time using the second module,
<em>Remove Occurrences by ID</em>. With the pointer, click on the record
in Bolivia. Information on the record will pop up, starting with the
OccID. In this case it is OccID #18 (it may be a different number for
you). Other information from the attribute table will be available. For
example, the record has no information (NA) on the institution code,
state/province, or basis. Since we know the OccID number, we can find
the full information associated in the Occurrences tab. Click there and
find the record. Here we can see it is a preserved specimen from the
Museum of Southwestern Biology (MSB). Go back to the map. Enter “18” for
the ID to be removed and “Remove Occurrence”. You will see the point
disappear again. Click reset to get it back again.</p>
<p>Next, click on the module <em>Spatial Thin</em>. This lets you
attempt to reduce the effects of spatial sampling bias by running a
thinning function on the points to filter out those less than a defined
distance from one another. We will use “10 km” as an example and thin
for each species separately by using the “Batch” option again.</p>
<p>We are now left with 35 points for <em>Bassaricyon alleni</em> and 21
for <em>Bassaricyon neblina</em> (your numbers may be different). You
can zoom in to see what the function did. Red points were retained and
blue ones were removed. Download the processed occurrence datasets as a
.csv file by clicking on the button in the “Save” tab. Reminder: the
data downloaded are only for the species currently in the species
menu.</p>
</div>
<div id="process-environmental-data" class="section level1">
<h1><a id="ProcEnv"></a>Process Environmental Data</h1>
<p>Now we will need to choose the study extent for modeling. This will
define the region from which “background” points are drawn for model
fitting. Background points are meant to sample the environments in the
total area available to the study species. Methods like Maxent are known
as presence-background techniques because they compare the predictor
variable values at background points to those at the occurrence points
(as opposed to presence-absence techniques, which require absence data).
In making decisions about the study extent, we want to avoid areas the
species has historically been unable to move to—for example, regions
beyond a barrier like a mountain range or large river that the species
cannot cross. Including these areas may send a false signal to the model
that these areas are not environmentally suitable. Like every other step
of the analysis, please see the relevant guidance text for more
details.</p>
<p>You can explore the different options for delineating the study
extent here. Each module has two steps: 1) choosing the shape of the
background extent, and 2) sampling the background points. To begin, go
to the module <em>Select Study Region</em>. Under “Step 1”, try out the
different options and see how each one draws the background shape. Try
increasing and decreasing the buffer to see how the shape is affected.
Now set the species to <em>B. neblina</em> and use <em>Select study
region</em> to a minimum convex polygon with a 0.7° buffer distance.
Then switch to <em>B. alleni</em> an</p>
<p>Alternatively, you can draw your own polygon (using the same polygon
drawing tool we tested in <strong>Component: Process occs</strong>). If
you have a file specifying the background extent, you can upload it with
the <em>User-specified Study Region</em> module. This module can accept
a shapefile (must include .shp, .shx, and .dbf files) or a .csv file of
polygon vertex coordinates with the field order: longitude, latitude.
Note that the polygon you draw or shape you upload needs to contain all
the occurrence points.</p>
<p>Next, complete “Step 2”, which both clips the rasters by the study
extent and samples the background points. Set the number of background
points to 10,000 (larger samples can be appropriate for larger extents
or those with finer resolution; see component guidance text), check
“Batch”, and click the “Sample” button.</p>
<p>You may find that requesting 10,000 background points exceeds the
number of grid cells in the background extent. The available number of
points will be given in the log window, and that amount can be used
instead of 10,000.</p>
<p>A .zip file of the clipped rasters (e.g., the environmental data
clipped to the extent of the background you just created) is available
to download in the “Save” tab. Make sure to toggle the species to
download the file for each one.</p>
</div>
<div id="characterize-environmental-space" class="section level1">
<h1><a id="Espace"></a>Characterize Environmental Space</h1>
<p><strong>Component: Characterize Environmental Space</strong> contains
multi-species analyses and is optional. Unlike some other components
which let you perform the modules in any order, the modules within
<strong>Characterize Environmental Space</strong> are sequential and
thus need to be performed consecutively (i.e., you can’t get an
<em>Occurrence Density Grid</em> without first performing an
<em>Environmental Ordination</em>).</p>
<p>Before we begin the Module: <em>Environmental Ordination</em>
analysis, you need to select two species to work with. If you had more
than two species uploaded, select two from the species menu drop-down.
Since we only have two uploaded, click in the species menu box and
select the second species. Both names will appear in the box
simultaneously—this functionality is currently only available for the
<strong>Characterize Environmental Space</strong> component.</p>
<p>Module: <em>Environmental Ordination</em> is for conducting an
ordination approach called Principal Component Analysis (PCA), that
maximizes the variation contained in the predictor variables into fewer
ones. To perform a PCA, select the variables available for both species
by checking/unchecking the bioclimatic variables. Choose between
“Occurrences Only” or “Occurrences &amp; Background” for the plot
selection and set the x- and y-axis components. The PCA Scatter Plot
appears in the Results tab.</p>
<p>You can also view the PCA correlation circle, PCA scree plot, and the
PCA results summary. For more information on these statistics and how to
evaluate the results, consult the module guidance text.</p>
<p>Next, run an <em>Occurrence Density Grid</em>. This calculates and
plots which part of the environmental space is occupied more densely by
the species and the availability of environmental conditions present
within the background extent. Darker areas represent higher occurrence
density. Areas within solid lines represent all environmental conditions
available in the background extent, and areas within dashed lines
represent the 50% most frequent ones</p>
<p>And calculate Niche overlap…</p>
<p>The niche overlap quantification is based on the occurrence and
background densities in the available environmental space estimated in
Module: <em>Occurrence Density Grid</em>. The overlap is quantified
using Schoener’s D metric. The environmental conditions covered only by
the niche of species 1 are shown in blue, the environmental conditions
covered only by the niche of species 2 are shown in red, and the
environmental conditions covered by both species, or the niche overlap,
is shown in purple. In the Similarity Test, if the observed overlap (red
line) is higher than 95% of the simulated overlaps (p-value &lt; 0.05),
we can consider the two species to be more similar than random, which is
not what we see here. Again, consult the module guidance texts for more
help to understand the analyses and help on evaluating the results.</p>
<p>Download the PCA results (.zip), density grid (.png), and overlap
plot (.png) from the “Save” tab.</p>
</div>
<div id="partition-occurrences" class="section level1">
<h1><a id="Part"></a>Partition Occurrences</h1>
<p>We have not built any distribution models yet, but before we do, we
will make decisions on how to partition our data for evaluation. In
order to determine the strength of the model’s predictive ability, you
theoretically need independent data to test it. When no independent
datasets exist, one solution is to partition your data into subsets that
we assume are independent of each other, then sequentially build a model
on all the subsets but one and evaluate the performance of this model on
the left-out subset. This is known as <em>k</em>-fold cross-validation
(where <em>k</em> is the total number of subsets, or ‘folds’), which is
quite prevalent in statistics, especially the fields of machine learning
and data science. After this sequential model-building exercise is
complete, <em>Wallace</em> averages the model performance statistics
over all the itinerations and then builds a model using
<strong>all</strong> the data.</p>
<p>There is a whole literature on how to best partition data for
evaluating models. One option is to simply partition randomly, but with
spatial data we run the risk that the groups are not spatially
independent of each other. The jackknife method (“leave-one-out”) is
recommended for species with small sample sizes and has previously been
used for modeling <em>Bassaricyon neblina</em>
<a href="https://doi.org/10.1093/jmammal/gyy012" target="_blank">(Gerstner
et al. 2018)</a> but may have long computational times.</p>
<p>Another option is to partition spatially—for example, by drawing
lines on a map to divide the data. Spatial partitioning with
<em>k</em>-fold cross-validation forces the model to predict into
regions that are distant from those used to train the model (note that
<em>Wallace</em> also excludes background points from regions
corresponding to the withheld partition). For <em>Bassaricyon
alleni</em>, environmental conditions in Colombia and Ecuador may differ
considerably from conditions in Bolivia. If the model has accurate
predictions on average on withheld spatially partitioned data, it likely
has good transferability, which means it can transfer well to the new
values of predictor variables (because distant areas are usually more
environmentally different than close ones). As always, please refer to
the guidance text for more details on all the types of partitioning
offered in Wallace. <br> Here’s an example of jacknife (<em>k</em> = n),
which assigns each point to its own partition group, so the number of
bins equals the number of occurrences.</p>
<p>Now here is an example of spatial blocking, which assigns each point
to one of four spatially separate partition groups.</p>
<p>We’ll use this last method now for faster computation, but it is
recommended to review the guidance text and other literature––and talk
to your peers!—to make an informed decision on partition methods.</p>
<p>Partition both species using Module: <em>Spatial Partition</em> Block
(<em>k</em> = 4) option.</p>
</div>
<div id="case-a" class="section level1">
<h1><a id="CaseA"></a>Case A</h1>
<p>Here the code for example A</p>
</div>
<div id="case-b" class="section level1">
<h1><a id="CaseB"></a>Case B</h1>
<p>Here the code for example B</p>
</div>
<div id="case-c" class="section level1">
<h1><a id="CaseC"></a>Case C</h1>
<p>Here the code for example C</p>
</div>
<div id="case-d" class="section level1">
<h1><a id="CaseD"></a>Case D</h1>
<p>Code for case D here</p>
</div>
<div id="save-load-session" class="section level1">
<h1><a id="Save"></a>Save &amp; Load Session</h1>
<p>Before we go into Modeling, let’s explore one of the great features
of Wallace v2, which is the ability to stop and save your progress to be
continued later. If you want to skip this step (and risk losing
everything if an error occurs except the data or results you have
downloaded), you can move on to <a href="#Model">Model</a>.</p>
<p>Click ‘Save Session’ within the “Save” tab. This tab is available
from any of the Components. This will save your progress as an RDS
(.rds) file, a file type used to save R objects. After it is saved, you
can hit the stop sign in the upper right corner or close the browser
window and exit R/RStudio. <em>Note: if the Wallace session is closed
before saving results and/or the session, all work will be
lost</em>.</p>
<p>When you are ready to resume, load Wallace again.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(wallace)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">#run_wallace()</span></span></code></pre></div>
<p>In the <strong>Intro</strong> component, use the “Load Prior Session”
tab to import your .rds session file.</p>
<p>A box will pop up– It looks like other <em>Wallace</em> warning
messages, but in this case it is indicating the session is loaded. It
may be necessary to reload your variables, using <strong>Occ
Data</strong> and <strong>Env Data</strong> as previously carried out.
You can now carry on with the previous analysis.</p>
</div>
<div id="model" class="section level1">
<h1><a id="Model"></a>Model</h1>
<p>We are now ready to build a distribution model. <em>Wallace v2.0</em>
provides two algorithm options; Maxent and BIOCLIM. For this vignette,
we’ll use Maxent, a machine learning method that can fit a range of
functions to patterns in the data, from simple (i.e., straight lines) to
complex (i.e., curvy or with lines that can change direction; these can
get jagged if complexity is not controlled). For more details on Maxent,
please consult the
<a href="https://biodiversityinformatics.amnh.org/open_source/maxent/" target="_blank">Maxent
website</a> abnd guidance text.<br />
Maxent is available to run through <code>maxnet</code> package or
through Java with the <code>maxent.jar</code> option. In the interest of
time and to avoid Java-related issues, let’s choose the following
modeling options:</p>
<ul>
<li><p>Choose maxnet</p></li>
<li><p>Select L, LQ, and H feature classes. These are the shapes that
can be fit to the data:</p>
<ul>
<li>L = Linear, e.g. temp + precip<br />
</li>
<li>Q = Quadratic, e.g. temp^2 + precip^2<br />
</li>
<li>H = Hinge, e.g. piecewise linear functions, like splines (think of a
series of lines that are connected together)<br />
</li>
</ul></li>
<li><p>Select regularization multipliers between 0.5 and 4 with a step
value of 0.5.</p>
<ul>
<li>Regularization is a penalty on model complexity.<br />
</li>
<li>Higher values = smoother, less complex models. Basically, all
predictor variable coefficients are shrunk progressively until some
reach 0, when they drop out of the model. Only those variables with the
greatest predictive contribution remain in the model.<br />
</li>
</ul></li>
<li><p>Keep “NO” selected for categorical variables. This option is to
indicate if any of your predictor variables are categorical, like soil
or vegetation classes.</p>
<ul>
<li>Had you loaded categorical variables, you would check here and then
indicate which of the rasters is categorical.</li>
</ul></li>
<li><p>Set Clamping? to “TRUE”. This will clamp the model predictions
(i.e., keep the environmental values more extreme than those present in
the background data to within the bounds of the background
data).</p></li>
<li><p>If you set Parallel? to “TRUE”, you can indicate the number of
cores for parallel processing.</p></li>
</ul>
<p>We will construct a model for <em>Bassaricyon neblina</em>, but note
that the Batch feature can be checked to run these selections for all
species you have uploaded.<br />
Make sure <em>Bassaricyon neblina</em> is selected in the species menu
and Batch is unchecked before hitting <strong>Run</strong>.</p>
<p>The 3 feature class combinations (L, LQ, H) x 8 regularization
multipliers (0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4) = 24 candidate models. The
hinge feature class (H) will enable substantial complexity in the
response, so it takes a bit longer to run than the simpler models.</p>
<p>The results appear in two tables of evaluation statistics, allowing
comparison of the different models you just built. The first table shows
the statistics for the full model and partition averages. There should
be 24 rows: one for each of the feature class / regularization
multiplier combinations. In the first table, statistics from the models
built from the 4 occurrence data partition groups (one withheld for each
iteration) are averaged. In the second table, the partition group
statistics averaged in the first table are shown, and thus it contains
96 rows (each of the 4 folds for each of the 24 models).</p>
<p>How do we choose the “best” model?<br />
There is a mountain of literature about this, and there is really no
single answer for all datasets. The model performance statistics AUC
(Area Under the Curve), OR (Omission Rate), and CBI (Continuous Boyce
Index) were calculated and averaged across our partitions, and AICc
(corrected Akaike information criterion) was instead calculated using
the model prediction of the full background extent (and all of the
thinned occurrence points). Although AICc does not incorporate the
cross-validation results, it does explicitly penalize model
complexity—hence, models with more parameters tend to have a worse AICc
score. It’s really up to the user to decide, and the guidance text has
some references which should help you learn more.</p>
<p>The evaluation metrics table can be sorted. First, we will prioritize
models that omitted few occurrence points in the predicted area during
cross-validation. Sort the results table in ascending order by
“or.10p.avg”, or the average omission rate when applying a 10-percentile
training presence threshold to the (withheld) validation data (see
guidance text for details). As we would prefer a model that does not
omit many withheld occurrences when it makes a range prediction, we are
prioritizing low values of “or.10p.avg”.</p>
<p>Let’s also look at average validation AUC values (where higher values
are better).</p>
<p>And AICc (where lower values are better)…</p>
<p>In our example, if we had chosen the model with the lowest AICc
score, we would have ended up with LQ_2. Note: your values may be
different.</p>
<p>Next to the <strong>Evaluation</strong> results, you can access the
Maxent <strong>Lambdas</strong> file (which describe the weights for
feature classes of each variable) for each of the models (changing the
candidate model in the drop-down box changes the output).</p>
<p>Use the “Save” tab to download the evaluation tables.</p>
</div>
<div id="visualize" class="section level1">
<h1><a id="Vis"></a>Visualize</h1>
<p>There are four modules for Visualization. We’ll save the first,
<em>Map Prediction</em>, for last. We’ll skip the fourth module,
<em>BIOCLIM Envelope Plot</em>, since we used Maxent instead of
BIOCLIM.<br />
The module <em>Maxent Evaluation Plots</em>, enables users to evaluate
the performance statistics across models. Graphs appear in the Results
tab. Below, see how the feature class and regularization multiplier
selections affect average validation AUC values.</p>
<p>We should also examine the <strong>response curves</strong>, which
show how the predicted suitability (y-axis) changes based on different
values of each variable (x-axis). For these curves, the marginal
response of one variable is shown while the other variables are held at
their mean values. If you want to see the results for a particular
model, select it by using the dropdown menu below the species box. Below
is a response curve for model LQ_2 for the mean precipitation of the
driest month (bio14).</p>
<p>Of course, you can also visualize model predictions on the map.
Predictions of suitability can be continuous (a range of values from low
to high) or binary (thresholded to two values: 0, unsuitable and 1,
suitable). We are visualizing predictions made with the “cloglog”
transformation, which converts the raw Maxent output (relative
occurrence rate) to a probabilistic scale between 0 and 1 to approximate
probability of presence (given key assumptions). Please see the module
guidance for information about Maxent model output scalings and
thresholding rules. Here is the mapped prediction for model LQ_2, no
threshold, in cloglog output.</p>
<p>Below is the mapped prediction of the same model, this time with the
threshold set to the 10-percentile training presence value (the
occurrence suitability value we used to calculate omission rates above
to help us select models). Some of the occurrence points will fall
outside the blue regions that represent suitable areas for
<em>Bassaricyon neblina</em>. For the 10-percentile training presence
value, as it represents not the lowest predicted suitability, but the
value greater than the 10% lowest, the expected omission would be 0.1
(i.e., 10% omitted).</p>
<p>Try mapping the prediction with the threshold set to the less strict
‘minimum training presence’ and notice the difference. You can also
threshold by a quantile of training presences that are omitted. Try
setting the quantile to different values and notice the change in
prediction.</p>
<p>You may have noticed the batch option is not available for this
component. Users need to select optimal models relative to each species,
therefore predictions can only be mapped individually. You can download
your Maxent or BIOCLIM evaluation plots, response curves, and map
predictions from the ”Save” tab. Note that this will download the
current plot. For instance, if you wanted to download the continuous
prediction, you’ll have to plot again, since we last plotted the
threshold map.</p>
</div>
<div id="model-transfer" class="section level1">
<h1><a id="Transfer"></a>Model Transfer</h1>
<p>Next, you can transfer the model to new locations and past/future
climate scenarios. “Transferring” simply means making predictions with
the selected model using new environmental values (i.e., those not used
for model building) and getting suitability predictions for new variable
ranges. <em>Note: This can also be referred to as “projecting” a model,
but do not confuse this with the GIS term typically used for changing
the coordinate reference system of a map.</em></p>
<p>This is potentially confusing because the cross-validation step we
used also transferred to new conditions. The spatial cross-validation
step iteratively forced models to predict to new areas (and thus likely
new environments), and the evaluation statistics summarized the ability
of the particular model settings to result in models that transfer
accurately. However, the final model that we used to make the
predictions we are visualizing was built with <em>all</em> the data (it
did not exclude any partition groups or the geographic areas they
correspond to). So the variable ranges associated with all of the
background points in our dataset were used in the model-building
process.</p>
<p>We are now taking this model and transferring it to variable ranges
that might not have been used in model-building (i.e., not represented
in the training data). Thus, these environmental values for different
places and times could be completely new to our model, even potentially
so different that we may be uncertain in the accuracy of our prediction.
This is because although the modeled variable responses remain the same,
predictions for variable values more extreme than the training data can
result in unexpected suitability predictions. For this reason, clamping
is often used to constrain model transfers (see below). Please see the
guidance text for more orientation regarding these “non-analog
conditions”.</p>
<p>Let’s begin with <em>Transfer to New Extent</em> and see if Peru has
suitable areas for the olinguito. In Step 1, use the polygon drawing
tool to draw around Peru with a 1-degree buffer and hit “Create”.
Alternatively, you can upload a shapefile or CSV file with records for
vertices with fields “longitude, latitude” to use as a study region.</p>
<p>In Step 2, choose a threshold to make a binary prediction or no
threshold for a continuous one and Transfer. Here, we see very low
suitability for most of Peru for the olinguito.</p>
<p>Note: to remove the outline of the polygon from the prediction, click
the Trashcan icon and “Clear all”.</p>
<p>If you initially used WorldClim or ecoClimate as environmental
variables, you can use <em>Transfer to New Time</em>. In Step 1, there
are three options to choose a study region; to draw a polygon, use the
same extent, or upload a polygon. In Step 2, you have the choice of
WorldClim or Ecoclimate for source variables. The choice depends on your
initial selection of environmental variables in <strong>Component: Env
Data</strong>. For WorldClim, select a time period, a global circulation
model, a representative concentration pathway (RCP), and a threshold.
Notice also that there are several global circulation models (GCMs) to
choose from—these all represent different efforts to model future
climate. Not all GCMs have raster data for each RCP. See the module
guidance text for more on RCPs and GCMs. Note: some databases have
phased out RCPs for Shared Socioeconomic Pathways (SSPs), so be advised
that some literature might use SSP terminology instead of RCP. For
ecoClimate, you can select a Atmospheric Oceanic General Circulation
Model (AOGCM), temporal scenario, and threshold.</p>
<p>The third module, <em>Transfer to User Environments</em>, gives users
the option to project their model to their own uploaded environmental
data. The first step is the same as before (select the study region),
but in the second step users can upload single-format rasters (.tif,
.asc) to use as new data for model projection. The rasters must have the
same extent and resolution (cell size), and the names of the files must
correspond to the environmental variables used in modeling. To assist,
there is a message “Your files must be named as: …” indicating the
correct file names to use.</p>
<p>We will skip the <em>Transfer to New Time</em> and <em>Transfer to
User Environments</em> and move on to to <em>Calculate Environmental
Similarity</em>.<br />
When transferring a model, there may be areas within our new ranges of
values that have high uncertainty because they are very different from
the values used in model-building. In order to visualize where these
areas are, we can use the fourth module, <em>Calculate Environmental
Similarity</em>, to plot a MESS map. MESS stands for (M)ultivariate
(E)nvironmental (S)imilarity (S)urface, and the map shows a continuous
scale of environmental difference from the training data used for
model-building, where increasing positive values mean more similar
(blue), and decreasing negative values mean more different (red); please
see the module guidance text for details. We can see that future climate
values at high elevation are more similar to our training data, whereas
those at lower elevations towards the coast are very different in some
places. We may therefore interpret that predicted suitability in these
areas has higher uncertainty.</p>
</div>
<div id="reproduce" class="section level1">
<h1><a id="Reprod"></a>Reproduce</h1>
<p>A major advantage of <em>Wallace</em> is reproducibility. The first
option within this component is downloading code to run the analysis.
While we were using <em>Wallace</em>, <code>R</code> code has been
running in the background, evident from the messages printed to the
<code>R</code> console. This option allows you to download a simplified
version of this code in the form of a condensed and annotated
<code>R</code> script. This script serves as documentation for the
analysis and can be shared. It can also be run to reproduce the
analysis, or edited to change aspects of it. The script can be
downloaded as several file types, but the R Markdown format (.Rmd),
which is a convenient format for combining <code>R</code> code and
notation text, can be run directly in <code>R</code>. For .pdf
downloads, the software TeX is necessary to be installed on your system.
Please see the text on this page for more details.</p>
<p>To download the script, select Rmd and click Download.</p>
<p>Now, you should have an .Rmd file that contains your complete
analysis. Modules from Wallace are indicated as headers denoted by
<strong>###</strong>.</p>
<p>You might want to open a new <code>R</code> window and try running
some of this code. Remember that later sections of code may depend on
things that were done earlier, so they may not all run if you skip
ahead. Note that any <strong>Env Space</strong> analysis will appear at
the end of the file. Also remember that if you close your
<em>Wallace</em> session you’ll lose your progress in the web browser
(but your .Rmd will be unaffected). If you use RStudio, you can open
this Rmd and click <strong>knit</strong> to compile your workflow into a
shareable html document.</p>
<p>You can also download the Metadata. <em>Wallace</em> generates and
provides a variety of metadata objects that facilitate documentation and
reproducibility by recording the user’s methodological decisions (e.g.,
parameter settings) and stores them in a Range Model Metadata Standards
object. This will download as a zip and contain a CSV file (.csv) for
each species.</p>
<p>The last module available in the <strong>Reproduce</strong> component
is <em>Reference packages</em>. Here, you can download the citations for
all the R-packages used in the analysis. To give people credit for the
underlying packages that make <em>Wallace</em> possible (and to document
your analyses properly), it is critical to cite the packages and their
version number. Remember, <em>Wallace</em> is modular and aims to
facilitate access to and use of many <code>R</code> packages being
produced by the biogeography research community. Please promote this by
citing packages…and think about making one of your own and adding it to
a future version of Wallace someday!</p>
</div>
<div id="conclusion" class="section level1">
<h1><a id="Con"></a>Conclusion</h1>
<p>We are currently working with various partners on exciting additions,
so stay tuned for future versions of <em>Wallace</em>. Until then, you
can always work in R after the session by modifying the .Rmd and
building on the analysis.</p>
<p>Thank you for following the <em>Wallace</em> v2 vignette. We hope you
learned more about the updated application, its features, and modeling
of species distributions and niches in general. We hate to be
repetitive, but we highly encourage you to read the guidance text,
follow up on the recommended publications, and hopefully let them lead
you to other relevant publications that can inform you further. Also,
remember to discuss these topics with your peers.</p>
<p>We encourage you to join the
<a href="https://groups.google.com/g/wallaceecomod" target="_blank">Wallace
Google Group</a>–we’d love to hear your thoughts, opinions, or
suggestions on how to make Wallace better for all users. Members can
post to the community and be updated on any future announcements. If you
find a bug in the software, it can be reported on the
<a href="https://github.com/wallaceEcoMod/wallace/issues" target="_blank">GitHub
issues page</a> or using the
<a href="https://forms.gle/UffoBCQnMZjWYjfk9" target="_blank">bug
reporting form</a>.</p>
</div>
<div id="acknowledgments" class="section level1">
<h1><a id="Ack"></a>Acknowledgments</h1>
<p><em>Wallace</em> was recognized as a finalist for the 2015 Ebbe
Nielsen Challenge of the Global Biodiversity Information Facility
(GBIF), and received prize funding.<br />
This material is based upon work supported by the National Science
Foundation under Grant Numbers DBI-1661510 (RPA; Robert P. Anderson),
DBI-1650241 (RPA), DEB-1119915 (RPA), DEB-1046328 (MEA; Matthew E.
Aiello-Lammens), DBI-1401312 (RM; Robert Muscarella), and funding from
the National Aeronautics and Space Administration grant 80NSSC18K0406
(MEB; Mary E. Blair). Any opinions, findings, and conclusions or
recommendations expressed in this material are those of the author(s)
and do not necessarily reflect the views of the NSF or NASA.</p>
</div>
<div id="resources" class="section level1">
<h1><a id="Res"></a>Resources</h1>
<p>Biomodelos <a href="https://wallaceecomod.github.io/" class="uri">https://wallaceecomod.github.io/</a></p>
<p>ENM2020 W19T2 Online open access Ecological Niche Modeling Course by
A.T. Peterson, summary of modeling, includes Walkthrough of Wallace V1
<a href="https://www.youtube.com/watch?v=kWNyNd2X1uo&amp;t=1226s" class="uri">https://www.youtube.com/watch?v=kWNyNd2X1uo&amp;t=1226s</a></p>
<p>Learn more about Olingos and the Olinguito <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3760134/" class="uri">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3760134/</a></p>
<p>Gerstner et al. (2018). <em>Revised distributional estimates for the
recently discovered olinguito (Bassaricyon neblina), with comments on
natural and taxonomic history.</em> <a href="https://doi.org/10.1093/jmammal/gyy012" class="uri">https://doi.org/10.1093/jmammal/gyy012</a></p>
</div>
<div id="references" class="section level1">
<h1><a id="Ref"></a>References</h1>
<p>Phillips, S.J., Anderson, R.P., Dudík, M., Schapire, R.E., Blair,
M.E. (2017). Opening the black box: an open-source release of Maxent.
<em>Ecography</em>, 40(7), 887-893.
<a href="https://doi.org/10.1111/ecog.03049" target="_blank">https://doi.org/10.1111/ecog.03049</a></p>
<p>Merow, C., Smith, M.J., Silander, J.A. (2013). A practical guide to
MaxEnt for modeling species’ distributions: What it does, and why inputs
and settings matter. <em>Ecography</em>, 36(10), 1058-1069.
<a href="https://doi.org/10.1111/j.1600-0587.2013.07872.x" target="_blank">https://doi.org/10.1111/j.1600-0587.2013.07872.x</a></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
